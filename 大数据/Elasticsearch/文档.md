#### 通过查询进行更新

```http
POST twitter/_update_by_query
{
  "script": {
    "inline": "ctx._source.count++",
    "lang": "painless"
  },
  "query": {
    "term": {
      "user": "kimchy"
    }
  }
}
```

#### 通过查询进行删除

```http
GET base_fulltext/_delete_by_query?slices=18&wait_for_completion=false
{
  "query": {
    "bool": {
      "filter": {
        "bool": {
          "must": [
            {
              "range": {
                "update_time": {
                  "lt": "2018-03-01 00:00:00",
                  "gt": "2018-02-01 00:00:00"
                }
              }
            }
          ]
        }
      }
    }
  }
}
```

注意：

1. 其内部原理是通过scroll拿到数据，再使用批量删除的接口来实现，所以可以使用scroll方面的优化，比如scroll的时间、分片数、批量等。又因为是通过scroll进行查询得到数据，所以提高查询速度也会提高删除的效率，比较典型的是使用`filter`、`constant_score`等方法。
2. 有时数据量过大（千万以上）时，删除效率很低（在我看来还是因为查询慢造成的连锁反应）甚至删除任务中断的情况，这种情况下可以试着将删除任务分成多个。比如在示例中是删除一个月的数据，但其实我们的目标是删除全年的数据。这种分割要尽可能的均衡，否则也不会特别理想。
3. 如果数据量过大，在请求参数中加入`wait_for_completion=false`，会返回一个任务ID。